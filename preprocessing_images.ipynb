{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing_images.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-VU_CVqAnPK"
      },
      "source": [
        "# Install the OpenSlide C library and Python bindings\n",
        "!apt-get install openslide-tools\n",
        "!pip install openslide-python\n",
        "!pip install tifffile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yO1MC8kA7xB"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from openslide import open_slide, __library_version__ as openslide_version, OpenSlide\n",
        "import os\n",
        "from PIL import Image\n",
        "from skimage.color import rgb2gray\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LsJSgd0BBmd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/',  force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n1EHt1-Lqq9"
      },
      "source": [
        "### Reading slides and mask ###\n",
        "slide_num = '110'\n",
        "\n",
        "slide_path = '/content/drive/My Drive/tumor/tumor_' + slide_num + '.tif'\n",
        "tumor_mask_path = '/content/drive/My Drive/cancer_detection/backup/annotation_mask/teste7/tumor_' + slide_num +'_mask.tif'\n",
        "\n",
        "slide = open_slide(slide_path)\n",
        "tumor_mask = open_slide(tumor_mask_path)\n",
        "\n",
        "print (\"Reading WSI from %s | width: %d, height: %d\" % (slide_path, \n",
        "                                                        slide.level_dimensions[0][0], \n",
        "                                                        slide.level_dimensions[0][1]))\n",
        "\n",
        "print (\"Reading annotation mask from %s | width: %d, height: %d\" % (tumor_mask_path, \n",
        "                                                        tumor_mask.level_dimensions[0][0], \n",
        "                                                        tumor_mask.level_dimensions[0][1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKj3bIMVM4qb"
      },
      "source": [
        "def read_slide(slide, x, y, level, width, height, as_float=False):\n",
        "    im = slide.read_region((x,y), level, (width, height))\n",
        "    im = im.convert('RGB') # drop the alpha channel\n",
        "    if as_float:\n",
        "        im = np.asarray(im, dtype=np.float32)\n",
        "    else:\n",
        "        im = np.asarray(im)\n",
        "    assert im.shape == (height, width, 3)\n",
        "    return im\n",
        "    \n",
        "slide_image = read_slide(slide, \n",
        "                         x=0, \n",
        "                         y=0, \n",
        "                         level=5, \n",
        "                         width=slide.level_dimensions[5][0], \n",
        "                         height=slide.level_dimensions[5][1])\n",
        "\n",
        "mask_image = read_slide(tumor_mask, \n",
        "                         x=0, \n",
        "                         y=0, \n",
        "                         level=5, \n",
        "                         width=slide.level_dimensions[5][0], \n",
        "                         height=slide.level_dimensions[5][1])\n",
        "#show figs\n",
        "#plt.figure(figsize=(10,10), dpi=100)\n",
        "#plt.imshow(slide_image)\n",
        "\n",
        "#plt.figure(figsize=(10,10), dpi=100)\n",
        "#plt.imshow(mask_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRt7NT7NakGF"
      },
      "source": [
        "FILTERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTahnZ9qNk0i"
      },
      "source": [
        "# From \"A method for normalizing histology slides for quantitative analysis\" - M Macenko, M Niethammer, JS Marron, D Borland, JT Woosley, G Xiaojun, C Schmitt, NE Thomas, IEEE ISBI, 2009. dx.doi.org/10.1109/ISBI.2009.5193250\n",
        "# Stain normalization method for H&E stained images\n",
        "def normalizeStaining(img, saveFile=None, Io=240, alpha=1, beta=0.15):\n",
        "             \n",
        "    HERef = np.array([[0.5626, 0.2159],\n",
        "                      [0.7201, 0.8012],\n",
        "                      [0.4062, 0.5581]])\n",
        "        \n",
        "    maxCRef = np.array([1.9705, 1.0308])\n",
        "    \n",
        "    # define height and width of image\n",
        "    h, w, c = img.shape\n",
        "    \n",
        "    # reshape image\n",
        "    img = img.reshape((-1,3))\n",
        "\n",
        "    # calculate optical density\n",
        "    OD = -np.log((img.astype(np.float)+1)/Io)\n",
        "    \n",
        "    # remove transparent pixels\n",
        "    ODhat = OD[~np.any(OD<beta, axis=1)]\n",
        "        \n",
        "    # compute eigenvectors\n",
        "    eigvals, eigvecs = np.linalg.eigh(np.cov(ODhat.T))\n",
        "        \n",
        "    # project on the plane spanned by the eigenvectors corresponding to the two \n",
        "    # largest eigenvalues    \n",
        "    That = ODhat.dot(eigvecs[:,1:3])\n",
        "    \n",
        "    phi = np.arctan2(That[:,1],That[:,0])\n",
        "    \n",
        "    minPhi = np.percentile(phi, alpha)\n",
        "    maxPhi = np.percentile(phi, 100-alpha)\n",
        "    \n",
        "    vMin = eigvecs[:,1:3].dot(np.array([(np.cos(minPhi), np.sin(minPhi))]).T)\n",
        "    vMax = eigvecs[:,1:3].dot(np.array([(np.cos(maxPhi), np.sin(maxPhi))]).T)\n",
        "    \n",
        "    # a heuristic to make the vector corresponding to hematoxylin first and the \n",
        "    # one corresponding to eosin second\n",
        "    if vMin[0] > vMax[0]:\n",
        "        HE = np.array((vMin[:,0], vMax[:,0])).T\n",
        "    else:\n",
        "        HE = np.array((vMax[:,0], vMin[:,0])).T\n",
        "    \n",
        "    # rows correspond to channels (RGB), columns to OD values\n",
        "    Y = np.reshape(OD, (-1, 3)).T\n",
        "    \n",
        "    # determine concentrations of the individual stains\n",
        "    C = np.linalg.lstsq(HE,Y, rcond=None)[0]\n",
        "    \n",
        "    # normalize stain concentrations\n",
        "    maxC = np.array([np.percentile(C[0,:], 99), np.percentile(C[1,:],99)])\n",
        "    tmp = np.divide(maxC,maxCRef)\n",
        "    C2 = np.divide(C,tmp[:, np.newaxis])\n",
        "    \n",
        "    # recreate the image using reference mixing matrix\n",
        "    Inorm = np.multiply(Io, np.exp(-HERef.dot(C2)))\n",
        "    Inorm[Inorm>255] = 254\n",
        "    plt.figure(figsize=(10,10), dpi=100)\n",
        "    Inorm = np.reshape(Inorm.T, (h, w, 3)).astype(np.uint8)  \n",
        "        \n",
        "    return Image.fromarray(Inorm)  \n",
        "\n",
        "#stain normalization\n",
        "nomr_img = normalizeStaining(img = slide_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjoSaGJpabUy"
      },
      "source": [
        "# Removing backround\n",
        "# I am not getting the resulting image from the stain normalization method, I am applying the filter to remove the background on the original image and creating a mask\n",
        "def grays_filter(rgb, tolerance=15):\n",
        "  \n",
        "  #Mask to filter out pixels where the red, green, and blue channel values are similar.\n",
        "  '''\n",
        "  Filtro para a área de sombra no slide (área de sombra = gradiente de tons de cinza escuro a claro). \n",
        "  Um pixel cinza tem valores de canal vermelho, verde e azul que estão próximos. \n",
        "  A função filter_grays () filtra os pixels que têm valores de vermelho, azul e verde que estão dentro de uma certa tolerância um do outro. \n",
        "  A tolerância padrão é 15. O filtro cinzas também filtra pixels brancos e pretos, pois eles têm valores semelhantes de vermelho, verde e azul.\n",
        "  '''\n",
        "  rgb = rgb.astype(np.int)\n",
        "  rg_diff = abs(rgb[:, :, 0] - rgb[:, :, 1]) <= tolerance\n",
        "  rb_diff = abs(rgb[:, :, 0] - rgb[:, :, 2]) <= tolerance\n",
        "  gb_diff = abs(rgb[:, :, 1] - rgb[:, :, 2]) <= tolerance\n",
        "  result = ~(rg_diff & rb_diff & gb_diff)\n",
        "\n",
        "  return result\n",
        "\n",
        "#background removal\n",
        "rgb = slide_image\n",
        "mask = grays_filter(rgb) # the mask is important, the background_removal_img is just to plot\n",
        "background_removal_img = rgb * np.dstack([mask, mask, mask])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1GUwgffafuF"
      },
      "source": [
        "#show figs\n",
        "plt.figure(figsize=(10,10), dpi=100)\n",
        "plt.imshow(nomr_img)\n",
        "\n",
        "plt.figure(figsize=(10,10), dpi=100)\n",
        "plt.imshow(background_removal_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84-dcaTpNvQh"
      },
      "source": [
        "### All filters together ###\n",
        "#after remove aplling mask to remove the background\n",
        "img_result = nomr_img * np.dstack([mask, mask, mask])\n",
        "\n",
        "#show figs\n",
        "#plt.figure(figsize=(5,5), dpi=100)\n",
        "#plt.imshow(img_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lngfdAU-QKzs"
      },
      "source": [
        "# making the image and the mask square to obtain patches with 256x256 (it need to be improvement)\n",
        "def square_image(img):  \n",
        "    #Getting the bigger side of the image\n",
        "    s = max(img.shape[0:2])\n",
        "\n",
        "    #Creating a dark square with NUMPY  \n",
        "    f = np.zeros((s,s,3),np.uint8)\n",
        "\n",
        "    #Getting the centering position\n",
        "    ax,ay = (s - img.shape[1])//2,(s - img.shape[0])//2\n",
        "\n",
        "    #Pasting the 'image' in a centering position\n",
        "    f[ay:img.shape[0]+ay,ax:ax+img.shape[1]] = img    \n",
        "    return f\n",
        "\n",
        "img_result_square = square_image(img_result)\n",
        "mask_image_square = square_image(mask_image)\n",
        "\n",
        "#show image\n",
        "#plt.figure(figsize=(10,10), dpi=100)\n",
        "#plt.imshow(img_result_square)\n",
        "\n",
        "#plt.figure(figsize=(10,10), dpi=100)\n",
        "#plt.imshow(mask_image_square)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhea8L60Q3le"
      },
      "source": [
        "#plotting the mask on the filtered image\n",
        "plt.figure(figsize=(10,10), dpi=100)\n",
        "plt.imshow(img_result_square)\n",
        "plt.imshow(mask_image_square, cmap='viridis', alpha=0.44)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMZpS7bl4sLI"
      },
      "source": [
        "CLASSIFICATION REGIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agJxsuZQ9kUJ"
      },
      "source": [
        "#Base directory\n",
        "\n",
        "train_dir = '/content/drive/My Drive/cancer_detection/paper/patch_train'\n",
        "val_dir = '/content/drive/My Drive/cancer_detection/paper/patch_val'\n",
        "test_dir = '/content/drive/My Drive/cancer_detection/paper/patch_test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIfgDZDMA5Jz"
      },
      "source": [
        "## Building train and validation pacthes\n",
        "\n",
        "img = img_result_square\n",
        "mask = mask_image_square\n",
        "\n",
        "patch_size = 256\n",
        "\n",
        "img_shape = img.shape\n",
        "mask_shape = mask.shape\n",
        "\n",
        "tile_size = (patch_size, patch_size)\n",
        "offset = (patch_size, patch_size)\n",
        "\n",
        "i_range = (int(math.ceil(img_shape[0]/(offset[1] * 1.0))))\n",
        "j_range= (int(math.ceil(img_shape[1]/(offset[0] * 1.0))))\n",
        "\n",
        "i=0\n",
        "j=0\n",
        "count_patch = 0\n",
        "count_zero = 0\n",
        "\n",
        "for i in range(i_range):\n",
        "  for j in range(j_range):\n",
        "    cropped_img = img[offset[1]*i:min(offset[1]*i+tile_size[1], img_shape[0]), offset[0]*j:min(offset[0]*j+tile_size[0], img_shape[1])]\n",
        "    cropped_img_mask = mask[offset[1]*i:min(offset[1]*i+tile_size[1], mask_shape[0]), offset[0]*j:min(offset[0]*j+tile_size[0], mask_shape[1])]\n",
        "    cont_zero_img = np.count_nonzero(cropped_img)\n",
        "    is_all_zero = np.all((cropped_img == 0)) # if the array contains just zero or count_zero is more than 50% of the image the patch is does considered. ---> DISCUSSING POINT <---\n",
        "    if is_all_zero or cont_zero_img < 32768: # -> 32768 is 50% from a 256x256 patch\n",
        "      count_zero += 1\n",
        "    else:\n",
        "      non_zero_img = np.count_nonzero(cropped_img)\n",
        "      non_zero_mask = np.count_nonzero(cropped_img_mask)\n",
        "      percent = (non_zero_mask/non_zero_img)*100\n",
        "      if count_patch % 5 == 0: # for each 5 patchs of train save one as validation \n",
        "        drive_path = val_dir\n",
        "        if percent > 10: # if the mask occupies a region greater than 10% of the non-zero pixel (tissues) the patch is classified as positive ---> DISCUSSING POINT <---\n",
        "          print('save' + slide_num + '_' + str(i) + '_' + str(j) + ': class 1')\n",
        "          plt.imsave(drive_path + '/1/' + slide_num + '_' + str(i) + '_' + str(j) + '.jpg', cropped_img)\n",
        "        else:\n",
        "          print('save' + slide_num + '_' + str(i) + '_' + str(j) + ': class 0')\n",
        "          plt.imsave(drive_path + '/0/' + slide_num + '_' + str(i) + '_' + str(j) + '.jpg', cropped_img)\n",
        "      else:\n",
        "        drive_path = train_dir\n",
        "        if percent > 10: \n",
        "          print('save' + slide_num + '_' + str(i) + '_' + str(j) + ': class 1')\n",
        "          plt.imsave(drive_path + '/1/' + slide_num + '_' + str(i) + '_' + str(j) + '.jpg', cropped_img)\n",
        "        else:\n",
        "          print('save' + slide_num + '_' + str(i) + '_' + str(j) + ': class 0')\n",
        "          plt.imsave(drive_path + '/0/' + slide_num + '_' + str(i) + '_' + str(j) + '.jpg', cropped_img)\n",
        "      count_patch +=1\n",
        "    j +=1\n",
        "  i +=1\n",
        "print('count_zero', count_zero)\n",
        "print('count_patch', count_patch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EBXp3a6Q-5M"
      },
      "source": [
        "## Building test pacthes\n",
        "img = img_result_square\n",
        "mask = mask_image_square\n",
        "\n",
        "patch_size = 256\n",
        "\n",
        "img_shape = img.shape\n",
        "mask_shape = mask.shape\n",
        "\n",
        "tile_size = (patch_size, patch_size)\n",
        "offset = (patch_size, patch_size)\n",
        "\n",
        "i_range = (int(math.ceil(img_shape[0]/(offset[1] * 1.0))))\n",
        "j_range= (int(math.ceil(img_shape[1]/(offset[0] * 1.0))))\n",
        "\n",
        "i=0\n",
        "j=0\n",
        "count_zero = 0\n",
        "drive_path = test_dir\n",
        "\n",
        "for i in range(i_range):\n",
        "  for j in range(j_range):\n",
        "    cropped_img = img[offset[1]*i:min(offset[1]*i+tile_size[1], img_shape[0]), offset[0]*j:min(offset[0]*j+tile_size[0], img_shape[1])]\n",
        "    cropped_img_mask = mask[offset[1]*i:min(offset[1]*i+tile_size[1], mask_shape[0]), offset[0]*j:min(offset[0]*j+tile_size[0], mask_shape[1])]\n",
        "    cont_zero_img = np.count_nonzero(cropped_img)\n",
        "    is_all_zero = np.all((cropped_img == 0)) # if the array contains just zero or count_zero is more than 50% of the image the patch is does considered. ---> DISCUSSING POINT <---\n",
        "    if is_all_zero or cont_zero_img < 32768: # -> 32768 is 50% from a 256x256 patch\n",
        "      count_zero += 1\n",
        "    else:\n",
        "      non_zero_img = np.count_nonzero(cropped_img)\n",
        "      non_zero_mask = np.count_nonzero(cropped_img_mask)\n",
        "      percent = (non_zero_mask/non_zero_img)*100\n",
        "      if percent > 10: # if the mask occupies a region greater than 10% of the non-zero pixel (tissues) the patch is classified as positive ---> DISCUSSING POINT <---\n",
        "        print('save' + slide_num + '_' + str(i) + '_' + str(j) + ': class 1')\n",
        "        plt.imsave(drive_path + '/1/' + slide_num + '_' + str(i) + '_' + str(j) + '.jpg', cropped_img)\n",
        "      else:\n",
        "        print('save' + slide_num + '_' + str(i) + '_' + str(j) + ': class 0')\n",
        "        plt.imsave(drive_path + '/0/' + slide_num + '_' + str(i) + '_' + str(j) + '.jpg', cropped_img)\n",
        "      if percent > 10: \n",
        "        print('save' + slide_num + '_' + str(i) + '_' + str(j) + ': class 1')\n",
        "        plt.imsave(drive_path + '/1/' + slide_num + '_' + str(i) + '_' + str(j) + '.jpg', cropped_img)\n",
        "      else:\n",
        "        print('save' + slide_num + '_' + str(i) + '_' + str(j) + ': class 0')\n",
        "        plt.imsave(drive_path + '/0/' + slide_num + '_' + str(i) + '_' + str(j) + '.jpg', cropped_img)\n",
        "    j +=1\n",
        "  i +=1\n",
        "print('count_zero', count_zero)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}